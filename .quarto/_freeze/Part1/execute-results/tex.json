{
  "hash": "2d2a1b559683811696eba5d40357f30c",
  "result": {
    "markdown": "---\ntitle: Testing ground for bachelor thesis\nauthor: MÃ©lanie Fournier\nformat:\n  html:\n    code-fold: true\n  pdf:\n    geometry:\n      - top=30mm\n      - left=20mm\n    number-sections: true\n    include-in-header:\n      text: |\n        \\usepackage{amsmath}\n        \\usepackage{easy-todo}\n        \\usepackage{amsthm}\n    documentclass: article\n    fontsize: '14'\n---\n\n# Explicit RK2 and stability function\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass testProblem:\n## Define it as \n    def __init__(self,b,n) -> None:\n        self.n = n\n        self.b = b\n        self.deltaX = 1 / (n+1)\n        self.M = self.buildM(b,n,self.deltaX)\n        self.e = self.buildE(n, self.deltaX)\n\n\n    def buildM(self,b,n,deltaX):\n        \"\"\"\n        we go from u0 to u(n+1).\n        \"\"\"\n        deltaX = 1 / (n+1)\n        A = deltaX *(np.eye(n) -1 * np.eye(n,k = -1))\n        B = b* (-2*np.eye(n) + np.eye(n, k = -1) + np.eye(n,k=1))\n        return A-B\n    \n    def buildE(self,n,deltaX):\n        return deltaX**2 *np.ones(n)\n    \n    def f(self,y):\n        return self.e - self.M@y\n    \n    def oneStepSmoother(self,y,t,deltaT,alpha):\n        \"\"\"\n        Perform one pseudo time step deltaT of the solver for the diff eq\n        y' = e - My = f(y). .\n        \"\"\"\n        k1 = self.f(y)\n        k2 = self.f(y + alpha*deltaT*k1)\n        yNext = y + deltaT*k2\n        return yNext\n    \n    def findOptimalParameters(self):\n        #This is where the reinforcement learning algorithm \n        #take place in\n        return 0 , 0\n    \n\n    def mainSolver(self,n_iter = 10):\n        \"\"\" Main solver for the problem, calculate the approximated solution\n        after n_iter pseudo time steps. \"\"\"\n        resNormList = np.zeros(n_iter+1)\n        t = 0\n        #Initial guess y = e\n        y = np.ones(e)\n        resNormList[0] = np.linalg.norm(self.M@y-self.e)\n        ##Finding the optimal params\n        alpha, deltaT = self.findOptimalParameters()\n        ##Will need to be removed, just for debugging\n        alpha = 0.5\n        deltaT = 0.00006\n        #For now, we use our best guess\n        for i in range(n_iter):\n            y = self.oneStepSmoother(y,t,deltaT,alpha)\n            t += deltaT\n            resNorm = np.linalg.norm(self.M@y - self.e)\n            resNormList[i+1] = resNorm\n        return y , resNormList\n\n    def mainSolver2(self,alpha, deltaT, n_iter = 10):\n        \"\"\" Like the main solver, except we give \n        the parameters explicitely \"\"\"\n        y = np.array([0.00719735, 0.01434065, 0.02142834, 0.02845879, 0.03543034,\n       0.04234128, 0.04918987, 0.05597432, 0.06269281, 0.06934346,\n       0.07592437, 0.08243356, 0.08886904, 0.09522877, 0.10151064,\n       0.10771254, 0.11383227, 0.11986762, 0.1258163 , 0.13167601,\n       0.13744437, 0.14311899, 0.1486974 , 0.15417709, 0.15955552,\n       0.16483009, 0.16999815, 0.175057  , 0.1800039 , 0.18483606,\n       0.18955064, 0.19414475, 0.19861545, 0.20295975, 0.20717461,\n       0.21125694, 0.21520361, 0.21901143, 0.22267715, 0.22619749,\n       0.22956911, 0.23278861, 0.23585255, 0.23875743, 0.24149971,\n       0.24407579, 0.246482  , 0.24871466, 0.25076999, 0.25264419,\n       0.25433339, 0.25583367, 0.25714106, 0.25825152, 0.25916098,\n       0.25986529, 0.26036025, 0.26064162, 0.26070509, 0.26054628,\n       0.26016077, 0.25954408, 0.25869166, 0.25759892, 0.25626119,\n       0.25467375, 0.25283181, 0.25073051, 0.24836496, 0.24573017,\n       0.2428211 , 0.23963265, 0.23615963, 0.23239681, 0.22833888,\n       0.22398045, 0.21931606, 0.2143402 , 0.20904726, 0.20343156,\n       0.19748735, 0.1912088 , 0.18458999, 0.17762494, 0.17030756,\n       0.16263169, 0.15459109, 0.14617941, 0.13739022, 0.12821701,\n       0.11865315, 0.10869192, 0.09832652, 0.08755003, 0.07635541,\n       0.06473555, 0.05268319, 0.04019099, 0.02725147, 0.01385704])\n        resNormList = np.zeros(n_iter+1)\n        t = 0\n        #Initial guess y = e\n        #y = np.ones(n)\n        resNormList[0] = np.linalg.norm(self.M@y-self.e)\n        #For now, we use our best guess\n        for i in range(n_iter):\n            y = self.oneStepSmoother(y,t,deltaT,alpha)\n            t += deltaT\n            resNorm = np.linalg.norm(self.M@y - self.e)\n            resNormList[i+1] = resNorm\n        return y , resNormList\n\n```\n:::\n\n\nWe now have everything we need to get going, let's plot the residual norm over iteration as a first test\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n#Create the object\nb = 0.5\nn = 100\n\nalpha = 0.13813813813813813\ndeltaT = 3.5143143143143143\nconvDiffProb = testProblem(b,n)\ny, resNormList = convDiffProb.mainSolver2(0.093093,5.6003,20)\n\nx = np.linspace(0,1,n+2) #Create space\nyTh = np.zeros(n+2)\nyTh[1:n+1] = np.linalg.solve(convDiffProb.M,convDiffProb.e)\n\nyApprox = np.zeros(n+2)\nyApprox[1:n+1] = y\nfig, (ax1,ax2) = plt.subplots(1,2)\n\nax1.plot(resNormList)\nax1.set_xlabel(\"Iteration\")\nax1.set_ylabel(\"Residual norm\")\nax1.set_yscale('log')\n\nax2.plot(x,yTh,label = 'Discretised solution')\nax2.plot(x,yApprox,label = \"iterative solution\")\nax2.legend()\n\nfig.show()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_6136/2529022355.py:27: UserWarning:\n\nMatplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Evolution of the residual norm over a number of iteration.](Part1_files/figure-pdf/cell-3-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom matplotlib import cm\nfrom matplotlib.ticker import LinearLocator\n\ndef resRatio(resNormList):\n    return resNormList[-1] / resNormList[-2]\n\n\n\nl = 100\ndeltaTgrid = np.linspace(0.9,10,l)\nalphaGrid = np.linspace(0,1,l)\n\ndeltaTgrid, alphaGrid = np.meshgrid(deltaTgrid,alphaGrid)\n\nresRatioGrid2 = np.zeros((l,l))\n\nfor i in range(l):\n    print(i)\n    for j in range(l):\n        #print('alpha', alphaGrid[j,0])\n        #print('deltaT', deltaTgrid[0,i])\n        y , resNormList = convDiffProb.mainSolver2(alphaGrid[j,i],deltaTgrid[j,i],10)\n        ratio = resRatio(resNormList)\n        #print('ratio', ratio)\n        resRatioGrid2[j,i] = resRatio(resNormList)\n\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n\n\nclippedRatio = np.clip(resRatioGrid2,0.8,0.9)\nsurf = ax.contour(deltaTgrid,alphaGrid,clippedRatio,levels = [0.8,0.85,0.9])\n\ntransformedContour = np.log(1/(1+np.exp(-clippedRatio+1)))\n\n\n\nprint(np.nanmin(resRatioGrid2))\nprint(np.argmin(resRatioGrid2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n10\n11\n12\n13\n14\n15\n16\n17\n18\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n0.9971231634706321\n952\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_6136/930702461.py:31: UserWarning:\n\nNo contour levels were found within the data range.\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Part1_files/figure-pdf/cell-4-output-13.pdf){fig-pos='H'}\n:::\n:::\n\n\nContour plot\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\ncp = ax.contour(deltaTgrid,alphaGrid,resRatioGrid2,levels = [0.83,0.86,0.88,0.9,1], cmap=cm.coolwarm, linewidth=0)\nax.clabel(cp)\n#ax.view_init(elev = 90,azim = 150)\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_6136/383841379.py:2: UserWarning:\n\nThe following kwargs were not used by contour: 'linewidth'\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Part1_files/figure-pdf/cell-5-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\nSurface plot\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\nax.plot_surface(deltaTgrid,alphaGrid,np.clip(resRatioGrid2,0.5,1), cmap=cm.coolwarm, linewidth=0)\nax.view_init(elev = 90,azim = 180)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Part1_files/figure-pdf/cell-6-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n\n# Make data.\nX = np.arange(-5, 5, 0.25)\nY = np.arange(-5, 5, 0.25)\nX, Y = np.meshgrid(X, Y)\nR = np.sqrt(X**2 + Y**2)\nZ = np.sin(R)\n\n# Plot the surface.\nsurf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n                       linewidth=0, antialiased=False)\n\n# Customize the z axis.\nax.set_zlim(-1.01, 1.01)\nax.zaxis.set_major_locator(LinearLocator(10))\n# A StrMethodFormatter is used automatically\nax.zaxis.set_major_formatter('{x:.02f}')\n\n# Add a color bar which maps values to colors.\nfig.colorbar(surf, shrink=0.5, aspect=5)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Part1_files/figure-pdf/cell-7-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nimport sys\nprint(sys.executable)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n/home/melanie/anaconda3/bin/python\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n:::\n\n\nNecessary functions go here.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef RK2(f,y,t,deltaT,alpha,**args):\n    \"\"\"Second order family of Rk2\n    c = [0,alpha], bT = [1-1/(2alpha), 1/(2alpha)] , a2,1 = alpha \"\"\"\n    k1 = f(t,y,**args)\n    k2 = f(t + alpha*deltaT, y + alpha*deltaT*k1,**args)\n    yNext = y + deltaT*(k1*(1-1/(2*alpha)) + k2 * 1/(2*alpha))\n    return yNext\n    \ndef buildM(b,n):\n    \"\"\"\n    we go from u0 to u(n+1).\n    \"\"\"\n    deltaX = 1 / (n+1)\n    A = 1/deltaX *(np.eye(n) -1 * np.eye(n,k = -1))\n    B = b/deltaX**2 * (-2*np.eye(n) + np.eye(n, k = -1) + np.eye(n,k=1))\n    return A-B\n\ndef buildE(n):\n    return np.ones(n)\n\ndef f(t,y,M,e):\n    return e - M@y\n\n\ndef mainSolver(deltaT, alpha,b,f = f,n_iter = 10,n_points=100):\n    t = 0\n    e = buildE(n_points)\n    M = buildM(b,n_points)\n    #First guess\n    y = np.copy(e)\n    resNorm = np.linalg.norm(M@y -e)\n\n    for i in range(n_iter):\n        y = RK2(f,y,t,deltaT,alpha,M = M,e = e)\n        t += deltaT\n        lastResNorm , resNorm = resNorm ,  np.linalg.norm(M@y - e)\n    return resNorm / lastResNorm\n```\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nmainSolver(0.0001,0.5,0.5)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n0.9678775609609744\n```\n:::\n:::\n\n\nTo facilitate everything, we discretise the space with 100 interior points only, and with parameter $b = 0.5$.\n\n\n\nThis is how the solution looks like with the discretisation\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nb = 0.5\nn = 100\n\nM = buildM(b,n)\ne = buildE(n)\n\nx = np.linspace(0,1,n+2)\nx2 = np.linspace(0,1,n)\n\nanalyticSol = x - (np.exp(-(1-x)/b)-np.exp(-1/b))/(1-np.exp(-1/b))\nu = np.linalg.solve(M,e)\n\nplt.plot(x,analyticSol,label = 'Analytical solution')\nplt.plot(x2,u,label = 'Discretised solution')\nplt.legend()\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n<matplotlib.legend.Legend at 0x7fc24c5de7c0>\n```\n\nDiscretised solution vs analytical solution\n:::\n\n::: {.cell-output .cell-output-display}\n![](Part1_files/figure-pdf/cell-12-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\nHow would changing the parameters affect the residuals ratio after 10 iterations?\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndeltaTGrid = np.linspace(0.00001,0.0001,100)\n\nratio = np.zeros(100)\ni = 0\nfor deltaT in deltaTGrid:\n    ratio[i] = mainSolver(deltaT,0.6,0.5)\n    i+=1\n\nplt.plot(deltaTGrid,ratio)\nplt.xlabel('Delta T')\nplt.ylabel('Ratio')\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\nText(0, 0.5, 'Ratio')\n```\n\nImpact of the choice of time step with the residual ratios.\n:::\n\n::: {.cell-output .cell-output-display}\n![](Part1_files/figure-pdf/cell-13-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\nHow would changing the RK parameter change the residual ratio after 10 iterations? Here we take the optimal delta T we found earlier.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n#fig-cap: Changing alpha does not do much...\nalphaGrid = np.linspace(0.01,0.99,100)\n\nratio = np.zeros(100)\ni = 0\nfor alpha in alphaGrid:\n    ratio[i] = mainSolver(0.00007,alpha,0.5)\n    i+=1\n\nplt.plot(alphaGrid,ratio)\nplt.xlabel('alpha')\nplt.ylabel('Ratio')\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nText(0, 0.5, 'Ratio')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Part1_files/figure-pdf/cell-14-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\nPendulum test\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ndef f(t,y):\n    g = 9.81\n    l = 1\n    f1 = y[1]\n    f2 = -g/l* np.sin(y[0])\n    return np.array([f1,f2])\n\n\n\n#Pendulum\ndeltaT = 0.01\nt_min = 0\nn = 1000\nt = t_min\ntArray = np.zeros(n+1)\ntArray[0] = t\ny = np.array([np.pi/2,0])\nyArray = np.zeros((n+1,2))\nyArray[0] = y\nfor i in range(n):\n    y = RK2(f,y,t,deltaT,0.9)\n    t+=deltaT\n    tArray[i+1] = t\n    yArray[i+1] = y\n\n\nplt.plot(tArray,yArray[:,0])\n```\n:::\n\n\n",
    "supporting": [
      "Part1_files/figure-pdf"
    ],
    "filters": []
  }
}